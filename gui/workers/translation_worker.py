"""ë°±ê·¸ë¼ìš´ë“œ ë²ˆì—­ ì‘ì—… ì›Œì»¤"""
from pathlib import Path
from PyQt6.QtCore import QThread, pyqtSignal


class TranslationWorker(QThread):
    """ë°±ê·¸ë¼ìš´ë“œ ë²ˆì—­ ì‘ì—…"""
    progress = pyqtSignal(int, str)  # (ì§„í–‰ë¥ , ë©”ì‹œì§€)
    finished = pyqtSignal(str, dict, list, int)  # (ì™„ë£Œ ë©”ì‹œì§€, ë¹„ìš© ì •ë³´, ë²ˆì—­ ì—”íŠ¸ë¦¬ ë¦¬ìŠ¤íŠ¸, ìƒˆë¡œ ë²ˆì—­í•œ íŒŒì¼ ìˆ˜)
    error = pyqtSignal(str)  # ì˜¤ë¥˜ ë©”ì‹œì§€

    def __init__(self, input_dir, output_dir, engine, source_lang, target_lang, selected_chapters=None, preview_mode=True, batch_size=1):
        super().__init__()
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.engine = engine
        self.source_lang = source_lang
        self.target_lang = target_lang
        self.selected_chapters = selected_chapters  # ì„ íƒëœ ì±•í„° ë¦¬ìŠ¤íŠ¸
        self.preview_mode = preview_mode  # ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ (ì„ì‹œ í´ë”ì—ë§Œ ì €ì¥)
        self.batch_size = batch_size  # ë°°ì¹˜ í¬ê¸° (1, 10, 50, 100)
        self.total_tokens = {"input": 0, "output": 0}
        self.total_cost = 0.0
        self.translation_entries = []  # ë²ˆì—­ í•­ëª© ë¦¬ìŠ¤íŠ¸
        self.game_type = None  # ê²Œì„ íƒ€ì… ('naninovel', 'unity_generic', 'unity_other')

    def _extract_from_bundles(self, bundle_files, output_path):
        """ë²ˆë“¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì„ íƒëœ ì±•í„°ë§Œ)"""
        import UnityPy
        from pathlib import Path

        extracted_files = []

        print(f"Starting bundle extraction from {len(bundle_files)} bundles")
        print(f"Selected chapters: {self.selected_chapters}")

        # ì„ íƒëœ ì±•í„°ì— í•´ë‹¹í•˜ëŠ” ë²ˆë“¤ë§Œ í•„í„°ë§
        bundles_to_extract = []
        for bundle_file in bundle_files:
            if self.selected_chapters:
                full_path = str(bundle_file).lower()
                for chapter in self.selected_chapters:
                    if chapter.lower() in full_path:
                        bundles_to_extract.append(bundle_file)
                        print(f"  âœ“ Bundle matched: {bundle_file.name} (chapter: {chapter})")
                        break
            else:
                bundles_to_extract.append(bundle_file)

        print(f"Bundles to extract: {len(bundles_to_extract)}")

        # ì¶”ì¶œ í´ë” ìƒì„±
        extract_dir = output_path / "_extracted"
        extract_dir.mkdir(parents=True, exist_ok=True)

        for bundle_file in bundles_to_extract:
            try:
                print(f"Processing bundle: {bundle_file.name}")
                env = UnityPy.load(str(bundle_file))

                text_assets_found = 0
                for obj in env.objects:
                    if obj.type.name == "TextAsset":
                        text_assets_found += 1
                        data = obj.read()

                        # í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
                        text_content = None
                        try:
                            # m_Scriptê°€ bytesì¸ ê²½ìš°
                            if isinstance(data.m_Script, bytes):
                                text_content = data.m_Script.decode('utf-8')
                            # m_Scriptê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                            elif isinstance(data.m_Script, str):
                                text_content = data.m_Script
                            # script ë˜ëŠ” text ì†ì„± ì‹œë„
                            elif hasattr(data, 'script'):
                                text_content = str(data.script)
                            elif hasattr(data, 'text'):
                                text_content = str(data.text)
                            else:
                                # ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
                                text_content = data.m_Script.decode('utf-8-sig')
                        except Exception as decode_err:
                            print(f"  âš  Failed to decode {data.m_Name}: {type(data.m_Script)} - {str(decode_err)}")
                            continue

                        if not text_content:
                            print(f"  âš  Empty content for {data.m_Name}")
                            continue

                        # íŒŒì¼ëª… ìƒì„± (ë²ˆë“¤ëª… ê¸°ë°˜)
                        bundle_name = bundle_file.stem.replace('.bundle', '')
                        output_file = extract_dir / f"{data.m_Name or bundle_name}.txt"

                        # ì €ì¥
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(text_content)

                        extracted_files.append(output_file)
                        print(f"  âœ“ Extracted: {output_file.name}")

                print(f"  Found {text_assets_found} TextAssets in {bundle_file.name}")

            except Exception as e:
                print(f"  âœ— Failed to process bundle {bundle_file.name}: {str(e)}")
                continue

        print(f"Total extracted files: {len(extracted_files)}")
        return extracted_files

    def run(self):
        try:
            from core.translator import UniversalTranslator
            from core.game_language_detector import GameLanguageDetector
            from security.secure_storage import SecureStorage
            import os

            self.progress.emit(3, "ê²Œì„ í˜•ì‹ ê°ì§€ ì¤‘...")

            # ê²Œì„ í˜•ì‹ ê°ì§€
            input_path = Path(self.input_dir)
            detector = GameLanguageDetector()
            format_info = detector.detect_game_format(input_path)
            self.game_type = format_info.get('game_type', 'unknown')

            print(f"ğŸ® ê²Œì„ í˜•ì‹: {self.game_type}")
            print(f"   - Naninovel: {format_info.get('is_naninovel', False)}")

            # RPG Maker ê²Œì„ ì²˜ë¦¬
            if self.game_type == 'rpgmaker':
                self.progress.emit(5, "RPG Maker ê²Œì„ ê°ì§€ë¨")
                return self._translate_rpgmaker_game()

            # ì¼ë°˜ Unity ê²Œì„ ì²˜ë¦¬
            if self.game_type in ['unity_generic', 'unity_other']:
                self.progress.emit(5, "ì¼ë°˜ Unity ê²Œì„ ê°ì§€ë¨")
                return self._translate_general_unity_game()

            self.progress.emit(5, "API í‚¤ í™•ì¸ ì¤‘...")

            # API í‚¤ ë¡œë“œ
            storage = SecureStorage()
            api_key = storage.get_api_key("claude")

            if not api_key and "Claude" in self.engine:
                self.error.emit("âŒ Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\n\nì„¤ì • â†’ API í‚¤ ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                return

            # API í‚¤ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
            if api_key:
                os.environ["ANTHROPIC_API_KEY"] = api_key

            self.progress.emit(10, "íŒŒì¼ ìŠ¤ìº” ì¤‘...")

            # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            output_path = Path(self.output_dir)
            output_path.mkdir(parents=True, exist_ok=True)

            # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
            files = []
            for ext in ['*.txt', '*.nani', '*.json', '*.csv']:
                found = list(input_path.glob(f"**/{ext}"))
                files.extend(found)
                if found:
                    print(f"Found {len(found)} {ext} files")

            # ë²ˆë“¤ íŒŒì¼ í™•ì¸ (ê²Œì„ í´ë”ì¸ ê²½ìš°)
            bundle_files = list(input_path.glob("**/*.bundle"))
            if bundle_files:
                print(f"Found {len(bundle_files)} bundle files")

            if not files and bundle_files:
                # ë²ˆë“¤ íŒŒì¼ì—ì„œ ì¶”ì¶œ
                self.progress.emit(8, "Unity ë²ˆë“¤ íŒŒì¼ ê°ì§€ë¨, ì¶”ì¶œ ì¤‘...")

                try:
                    files = self._extract_from_bundles(bundle_files, output_path)
                    if not files:
                        self.error.emit("âŒ ë²ˆë“¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                        return
                    self.progress.emit(10, f"{len(files)}ê°œ íŒŒì¼ ì¶”ì¶œ ì™„ë£Œ")
                except Exception as e:
                    self.error.emit(f"âŒ ë²ˆë“¤ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                    return

            # ì±•í„° í•„í„°ë§
            if self.selected_chapters:
                original_count = len(files)
                filtered_files = []
                for file_path in files:
                    file_name = file_path.name
                    full_path = str(file_path).lower()

                    # ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ ì œì™¸
                    if any(x in file_name for x in ["_KOREAN", "_KO", "_CLAUDE"]):
                        continue

                    # ì„ íƒëœ ì±•í„°ì— ì†í•˜ëŠ”ì§€ í™•ì¸ (íŒŒì¼ëª… + ê²½ë¡œ)
                    for chapter in self.selected_chapters:
                        chapter_lower = chapter.lower()
                        if chapter_lower in file_name.lower() or chapter_lower in full_path:
                            filtered_files.append(file_path)
                            print(f"  âœ“ Matched: {file_path.name} (chapter: {chapter})")
                            break

                files = filtered_files
                print(f"Chapter filtering: {original_count} â†’ {len(files)} files")

                # í•„í„°ë§ í›„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê²½ê³ 
                if not files and bundle_files:
                    print(f"No text files matched chapters, trying bundles...")
                    self.progress.emit(8, "í…ìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ, Unity ë²ˆë“¤ì—ì„œ ì¶”ì¶œ ì‹œë„...")
                    try:
                        files = self._extract_from_bundles(bundle_files, output_path)
                        if files:
                            print(f"Extracted {len(files)} files from bundles")
                            # ì¶”ì¶œëœ íŒŒì¼ì— ë‹¤ì‹œ ì±•í„° í•„í„°ë§ ì ìš©
                            filtered_files = []
                            for file_path in files:
                                for chapter in self.selected_chapters:
                                    if chapter.lower() in str(file_path).lower():
                                        filtered_files.append(file_path)
                                        break
                            files = filtered_files
                            print(f"After filtering extracted files: {len(files)} files")
                    except Exception as e:
                        print(f"Bundle extraction failed: {str(e)}")

                self.progress.emit(12, f"ì±•í„° í•„í„°ë§: {original_count}ê°œ â†’ {len(files)}ê°œ")
            else:
                # ì±•í„° ì„ íƒ ì•ˆ ë¨ - ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ë§Œ ì œì™¸
                original_count = len(files)
                files = [f for f in files if not any(x in f.name for x in ["_KOREAN", "_KO", "_CLAUDE"])]
                print(f"Excluding translated files: {original_count} â†’ {len(files)} files")

            if not files:
                print(f"ERROR: No files to translate in {input_path}")
                print(f"Total files found before filtering: {len(files)}")
                self.error.emit("âŒ ë²ˆì—­í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\n\nì…ë ¥ í´ë”ì— ì›ë³¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\nì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼(_KOREAN, _KO, _CLAUDE)ì€ ì œì™¸ë©ë‹ˆë‹¤.")
                return

            self.progress.emit(15, f"{len(files)}ê°œ íŒŒì¼ ë°œê²¬")

            # ë²ˆì—­ê¸° ì´ˆê¸°í™” (ì„ íƒëœ ì–¸ì–´ë¡œ)
            translator = UniversalTranslator(
                rules_file="config/translation_rules.yaml",
                glossary_file="config/glossary.yaml",
                source_lang=self.source_lang,
                target_lang=self.target_lang
            )

            self.progress.emit(20, "ë²ˆì—­ ì‹œì‘...")

            print(f"ğŸš€ ë²ˆì—­ ë£¨í”„ ì‹œì‘")
            print(f"   ë²ˆì—­í•  íŒŒì¼ ìˆ˜: {len(files)}")
            print(f"   ì¶œë ¥ ê²½ë¡œ: {output_path}")

            # íŒŒì¼ë³„ ë²ˆì—­
            translated_count = 0
            skipped_count = 0

            for i, file_path in enumerate(files):
                progress_pct = 20 + int((i / len(files)) * 75)
                self.progress.emit(progress_pct, f"ë²ˆì—­ ì¤‘: {file_path.name} ({i+1}/{len(files)})")
                print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path.name} ({i+1}/{len(files)})")

                try:
                    # ì´ë¯¸ ë²ˆì—­ëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ì¶œë ¥ ê²½ë¡œì— ë™ì¼í•œ íŒŒì¼ëª…ì´ ì¡´ì¬í•˜ëŠ”ì§€)
                    if "_extracted" in str(file_path):
                        parts = Path(file_path).parts
                        extracted_idx = parts.index("_extracted")
                        relative_parts = parts[extracted_idx + 1:]
                        relative_path = Path(*relative_parts) if relative_parts else Path(file_path.name)
                    else:
                        try:
                            relative_path = file_path.resolve().relative_to(input_path.resolve())
                        except ValueError:
                            relative_path = Path(file_path.name)

                    output_file = output_path / relative_path

                    # ì¶œë ¥ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê±´ë„ˆë›°ê¸°
                    if output_file.exists():
                        print(f"â­ï¸ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ë²ˆì—­ë¨): {file_path.name}")
                        skipped_count += 1

                        # ê±´ë„ˆë›´ íŒŒì¼ì˜ ë²ˆì—­ ì—”íŠ¸ë¦¬ë„ ë¡œë“œ (Excel ë‚´ë³´ë‚´ê¸°ìš©)
                        try:
                            with open(output_file, 'r', encoding='utf-8') as f:
                                translated_lines = f.readlines()

                            with open(file_path, 'r', encoding='utf-8') as f:
                                original_lines = f.readlines()

                            from core.excel_manager import TranslationEntry

                            # ì¼ë³¸ì–´ ì£¼ì„ì—ì„œ ì›ë¬¸ ì¶”ì¶œ
                            for idx, line in enumerate(original_lines):
                                stripped = line.strip()

                                # ì£¼ì„(ì¼ë³¸ì–´ ì›ë¬¸) ë°œê²¬
                                if stripped.startswith(';') and not stripped.startswith('; >') and not stripped.startswith('; æ—¥æœ¬èª'):
                                    japanese_text = stripped[1:].strip()  # '; ' ì œê±°

                                    if japanese_text:
                                        # ë²ˆì—­ íŒŒì¼ì˜ ëŒ€ì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸° (idx+1ë¶€í„° ì‹œì‘)
                                        korean_idx = idx + 1
                                        while korean_idx < len(translated_lines):
                                            korean_line = translated_lines[korean_idx].strip()
                                            # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„/ë©”íƒ€ë°ì´í„°ê°€ ì•„ë‹ˆë©´ í•œêµ­ì–´ ë²ˆì—­
                                            if korean_line and not korean_line.startswith('#') and not korean_line.startswith(';'):
                                                entry = TranslationEntry(
                                                    file_path=str(file_path),
                                                    line_number=korean_idx + 1,
                                                    japanese=japanese_text,
                                                    translation=korean_line
                                                )
                                                self.translation_entries.append(entry)
                                                break
                                            korean_idx += 1

                        except Exception as e:
                            print(f"âš ï¸ ê±´ë„ˆë›´ íŒŒì¼ ì—”íŠ¸ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {file_path.name} - {str(e)}")

                        continue

                    # íŒŒì¼ ì½ê¸°
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()

                    # ë²ˆì—­í•  ë¼ì¸ ìˆ˜ì§‘ (ì£¼ì„ì˜ ì¼ë³¸ì–´ ì›ë¬¸ ì¶”ì¶œ)
                    texts_to_translate = []  # ì¼ë³¸ì–´ ì›ë¬¸
                    line_indices = []  # ë®ì–´ì“¸ ì¤‘êµ­ì–´ ë¼ì¸ ì¸ë±ìŠ¤ (ì‹œì‘, ë)
                    japanese_originals = []  # Excelìš© ì¼ë³¸ì–´ ì›ë¬¸

                    for idx, line in enumerate(lines):
                        stripped = line.strip()

                        # ì£¼ì„(;ë¡œ ì‹œì‘)ì´ë©´ì„œ ë©”íƒ€ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš° (ì¼ë³¸ì–´ ì›ë¬¸)
                        if stripped.startswith(';') and not stripped.startswith('; >') and not stripped.startswith('; æ—¥æœ¬èª'):
                            # ì£¼ì„ ì œê±°í•˜ê³  ì¼ë³¸ì–´ ì›ë¬¸ë§Œ ì¶”ì¶œ
                            japanese_text = stripped[1:].strip()  # '; ' ì œê±°

                            if japanese_text:  # ë¹ˆ ì£¼ì„ì´ ì•„ë‹ˆë©´
                                # ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘í•´ì„œ ì¤‘êµ­ì–´ ë²ˆì—­ì´ ëª‡ ì¤„ì¸ì§€ ì°¾ê¸°
                                chinese_start = idx + 1
                                chinese_end = chinese_start

                                # ë‹¤ìŒ #ì´ë‚˜ ; ë˜ëŠ” ë¹ˆ ì¤„ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ì¤‘êµ­ì–´ ë¼ì¸ ì°¾ê¸°
                                while chinese_end < len(lines):
                                    line_content = lines[chinese_end].strip()
                                    # ë¹ˆ ì¤„ì´ê±°ë‚˜ #ì´ë‚˜ ;ë¡œ ì‹œì‘í•˜ë©´ ì¤‘ë‹¨
                                    if not line_content or line_content.startswith('#') or line_content.startswith(';'):
                                        break
                                    chinese_end += 1

                                # ì¤‘êµ­ì–´ ë¼ì¸ì´ ìˆìœ¼ë©´ ì¶”ê°€
                                if chinese_end > chinese_start:
                                    texts_to_translate.append(japanese_text)
                                    line_indices.append((chinese_start, chinese_end))  # (ì‹œì‘, ë) íŠœí”Œ
                                    japanese_originals.append(japanese_text)

                    if not texts_to_translate:
                        continue

                    # ë°°ì¹˜ ë²ˆì—­
                    translated_lines = []

                    if self.batch_size == 1:
                        # ê°œë³„ ë²ˆì—­ (ê¸°ì¡´ ë°©ì‹)
                        for text in texts_to_translate:
                            translated = translator.translate(text)
                            translated_lines.append(translated)

                            # í† í° ì •ë³´ ìˆ˜ì§‘ (ì¶”ì •)
                            self.total_tokens["input"] += len(text) * 2
                            self.total_tokens["output"] += len(translated) * 2
                    else:
                        # ë°°ì¹˜ ë²ˆì—­ (10ê°œ, 50ê°œ, 100ê°œì”©)
                        for batch_start in range(0, len(texts_to_translate), self.batch_size):
                            batch = texts_to_translate[batch_start:batch_start + self.batch_size]
                            translated_batch = translator.translate_batch(batch)
                            translated_lines.extend(translated_batch)

                            # í† í° ì •ë³´ ìˆ˜ì§‘ (ì¶”ì •)
                            self.total_tokens["input"] += sum(len(t) * 2 for t in batch)
                            self.total_tokens["output"] += sum(len(t) * 2 for t in translated_batch)

                    # ë²ˆì—­ ì—”íŠ¸ë¦¬ ìƒì„± (Excel ë‚´ë³´ë‚´ê¸°ìš©)
                    from core.excel_manager import TranslationEntry
                    for idx_range, original, translated in zip(line_indices, japanese_originals, translated_lines):
                        # idx_rangeëŠ” (start, end) íŠœí”Œ
                        chinese_start, chinese_end = idx_range
                        entry = TranslationEntry(
                            file_path=str(file_path),
                            line_number=chinese_start + 1,  # Excelì—ëŠ” ì²« ë²ˆì§¸ ì¤‘êµ­ì–´ ë¼ì¸ ë²ˆí˜¸ í‘œì‹œ
                            japanese=original,
                            translation=translated
                        )
                        self.translation_entries.append(entry)

                    # ë²ˆì—­ëœ ë‚´ìš©ìœ¼ë¡œ ì¤‘êµ­ì–´ ë¼ì¸ ë®ì–´ì“°ê¸°
                    for idx_range, translated in zip(line_indices, translated_lines):
                        chinese_start, chinese_end = idx_range

                        # ì²« ë²ˆì§¸ ì¤‘êµ­ì–´ ë¼ì¸ì„ í•œêµ­ì–´ ë²ˆì—­ìœ¼ë¡œ êµì²´
                        lines[chinese_start] = translated + '\n'

                        # ë‚˜ë¨¸ì§€ ì¤‘êµ­ì–´ ë¼ì¸ë“¤ì€ ì‚­ì œ (ë¹ˆ ì¤„ë¡œ í‘œì‹œ)
                        for i in range(chinese_start + 1, chinese_end):
                            lines[i] = ''

                    # ì¶œë ¥ íŒŒì¼ ì €ì¥
                    # ë²ˆë“¤ ì¶”ì¶œ íŒŒì¼ì¸ ê²½ìš° (_extracted í´ë” ë‚´)
                    if "_extracted" in str(file_path):
                        # _extracted ì´í›„ ê²½ë¡œë§Œ ì‚¬ìš©
                        parts = Path(file_path).parts
                        extracted_idx = parts.index("_extracted")
                        relative_parts = parts[extracted_idx + 1:]
                        relative_path = Path(*relative_parts) if relative_parts else Path(file_path.name)
                    else:
                        # ì¼ë°˜ íŒŒì¼ì€ ì…ë ¥ í´ë” ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                        try:
                            relative_path = file_path.resolve().relative_to(input_path.resolve())
                        except ValueError:
                            # ìƒëŒ€ ê²½ë¡œ ê³„ì‚° ì‹¤íŒ¨ ì‹œ íŒŒì¼ëª…ë§Œ ì‚¬ìš©
                            relative_path = Path(file_path.name)

                    output_file = output_path / relative_path
                    output_file.parent.mkdir(parents=True, exist_ok=True)

                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.writelines(lines)

                    translated_count += 1

                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ë²ˆì—­ ì‹¤íŒ¨: {file_path.name} - {str(e)}")
                    continue

            # ë¹„ìš© ê³„ì‚°
            cost_info = self.calculate_cost()

            print(f"ğŸ‰ ë²ˆì—­ ë£¨í”„ ì™„ë£Œ")
            print(f"   ë²ˆì—­í•œ íŒŒì¼: {translated_count}ê°œ")
            print(f"   ê±´ë„ˆë›´ íŒŒì¼: {skipped_count}ê°œ")
            print(f"   ì´ íŒŒì¼: {len(files)}ê°œ")

            self.progress.emit(100, "ë²ˆì—­ ì™„ë£Œ!")

            # ì™„ë£Œ ë©”ì‹œì§€ ìƒì„±
            total_files = len(files)
            if self.preview_mode:
                message = f"âœ… ë²ˆì—­ ì™„ë£Œ (ë¯¸ë¦¬ë³´ê¸°)\n\n"
                message += f"ğŸ“Š ì´ {total_files}ê°œ íŒŒì¼:\n"
                message += f"   - âœ… ìƒˆë¡œ ë²ˆì—­: {translated_count}ê°œ\n"
                if skipped_count > 0:
                    message += f"   - â­ï¸ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ë²ˆì—­ë¨): {skipped_count}ê°œ\n"
                message += f"\nğŸ“ ì„ì‹œ í´ë”: {self.output_dir}\n\n"
                message += f"âœ… í™•ì¸ í›„ 'ê²Œì„ì— ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
            else:
                message = f"âœ… ë²ˆì—­ ì™„ë£Œ\n\n"
                message += f"ğŸ“Š ì´ {total_files}ê°œ íŒŒì¼:\n"
                message += f"   - âœ… ìƒˆë¡œ ë²ˆì—­: {translated_count}ê°œ\n"
                if skipped_count > 0:
                    message += f"   - â­ï¸ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ë²ˆì—­ë¨): {skipped_count}ê°œ\n"
                message += f"\nğŸ“ ì¶œë ¥: {self.output_dir}"

            self.finished.emit(message, cost_info, self.translation_entries, translated_count)

        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"ERROR: {error_detail}")
            self.error.emit(f"âŒ ì˜¤ë¥˜ ë°œìƒ:\n{str(e)}")

    def _find_patterns(self, texts: list, min_count: int = 5) -> dict:
        """ë°˜ë³µ íŒ¨í„´ ì°¾ê¸° (ìˆ«ìê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸)"""
        import re
        from collections import defaultdict

        pattern_map = defaultdict(list)

        for text in texts:
            if re.search(r'\d+', text):  # ìˆ«ì í¬í•¨ëœ ê²½ìš°ë§Œ
                pattern = re.sub(r'\d+', '{NUM}', text)
                numbers = re.findall(r'\d+', text)
                pattern_map[pattern].append({
                    'text': text,
                    'numbers': numbers
                })

        # min_count ì´ìƒë§Œ í•„í„°ë§
        return {
            p: items for p, items in pattern_map.items()
            if len(items) >= min_count
        }

    def _load_dictionary(self, dict_path: str) -> dict:
        """ì‚¬ì „ íŒŒì¼ ë¡œë“œ"""
        import json
        from pathlib import Path

        path = Path(dict_path)
        if path.exists():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {dict_path} - {str(e)}")
                return {}
        return {}

    def calculate_cost(self):
        """API ì‚¬ìš© ë¹„ìš© ê³„ì‚°"""
        cost_info = {
            "engine": self.engine,
            "input_tokens": self.total_tokens["input"],
            "output_tokens": self.total_tokens["output"],
            "total_cost": 0.0,
            "currency": "USD"
        }

        # ì—”ì§„ë³„ ê°€ê²© (per 1M tokens)
        pricing = {
            "Claude Haiku 3.5": {"input": 1.0, "output": 5.0},
            "Claude Sonnet 4": {"input": 3.0, "output": 15.0},
            "ChatGPT-4o": {"input": 2.5, "output": 10.0},
            "ChatGPT-4o-mini": {"input": 0.15, "output": 0.60},
        }

        for engine_key, prices in pricing.items():
            if engine_key in self.engine:
                input_cost = (self.total_tokens["input"] / 1_000_000) * prices["input"]
                output_cost = (self.total_tokens["output"] / 1_000_000) * prices["output"]
                cost_info["total_cost"] = input_cost + output_cost
                break

        return cost_info

    def _translate_general_unity_game(self):
        """ì¼ë°˜ Unity ê²Œì„ ë²ˆì—­ ì²˜ë¦¬ (cli ë„êµ¬ ì‚¬ìš©)"""
        try:
            from cli.extractor import UnityTextExtractor
            from core.translator import UniversalTranslator
            from security.secure_storage import SecureStorage
            import os

            input_path = Path(self.input_dir)
            output_path = Path(self.output_dir)
            output_path.mkdir(parents=True, exist_ok=True)

            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            self.progress.emit(10, "Unity ê²Œì„ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
            print(f"ğŸ“¦ Extracting from: {input_path}")

            extractor = UnityTextExtractor(input_path)
            entries = extractor.extract()

            if not entries or len(entries) == 0:
                self.error.emit(
                    "âŒ ë²ˆì—­ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                    "ê°€ëŠ¥í•œ ì›ì¸:\n"
                    "- ê²Œì„ì´ IL2CPPë¡œ ì»´íŒŒì¼ë¨\n"
                    "- í…ìŠ¤íŠ¸ê°€ ì•”í˜¸í™”ë˜ì–´ ìˆìŒ\n"
                    "- ì§€ì›í•˜ì§€ ì•ŠëŠ” Unity ë²„ì „"
                )
                return

            self.progress.emit(20, f"{len(entries)}ê°œ í…ìŠ¤íŠ¸ í•­ëª© ë°œê²¬")
            print(f"âœ… Found {len(entries)} translatable texts")

            # 2. API í‚¤ í™•ì¸
            self.progress.emit(25, "API í‚¤ í™•ì¸ ì¤‘...")
            storage = SecureStorage()

            api_key = None
            if "Claude" in self.engine:
                api_key = storage.get_api_key("claude")
                if not api_key:
                    self.error.emit("âŒ Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                    return
                os.environ["ANTHROPIC_API_KEY"] = api_key

            # 3. ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ (ë²ˆì—­ ë©”ëª¨ë¦¬)
            existing_json = output_path / "extracted_translated.json"
            existing_translations = {}

            if existing_json.exists():
                self.progress.emit(28, "ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ ì¤‘...")
                try:
                    import json
                    with open(existing_json, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    for entry_data in data.get('entries', []):
                        original_text = entry_data.get('text', '')
                        translated_text = entry_data.get('translated', '')
                        if original_text and translated_text:
                            existing_translations[original_text] = translated_text

                    print(f"âœ… ê¸°ì¡´ ë²ˆì—­ {len(existing_translations)}ê°œ ë¡œë“œë¨")
                except Exception as e:
                    print(f"âš ï¸ ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

            # 4. ë²ˆì—­
            self.progress.emit(30, f"{len(entries)}ê°œ í•­ëª© ë²ˆì—­ ì‹œì‘...")

            translator = UniversalTranslator(
                source_lang=self.source_lang,
                target_lang=self.target_lang,
                engine=self.engine
            )

            translated_count = 0
            skipped_count = 0

            for i, entry in enumerate(entries):
                try:
                    progress_pct = 30 + int((i / len(entries)) * 60)
                    self.progress.emit(progress_pct, f"ë²ˆì—­ ì¤‘... ({i+1}/{len(entries)})")

                    # ê¸°ì¡´ ë²ˆì—­ í™•ì¸
                    if entry.text in existing_translations:
                        entry.translated = existing_translations[entry.text]
                        skipped_count += 1
                        continue

                    # ìƒˆë¡œìš´ í•­ëª©ë§Œ ë²ˆì—­
                    translation = translator.translate(entry.text)
                    entry.translated = translation
                    translated_count += 1

                    # í† í° ë° ë¹„ìš© ëˆ„ì 
                    if hasattr(translator, 'last_usage'):
                        usage = translator.last_usage
                        self.total_tokens["input"] += usage.get("input_tokens", 0)
                        self.total_tokens["output"] += usage.get("output_tokens", 0)

                    # ì£¼ê¸°ì ìœ¼ë¡œ ì €ì¥
                    if (i + 1) % 10 == 0:
                        extractor.entries = entries
                        extractor.save(output_path / "extracted_translated.json")

                except Exception as e:
                    print(f"âš ï¸ Translation error: {str(e)}")
                    continue

            # 4. ìµœì¢… ì €ì¥
            self.progress.emit(90, "ë²ˆì—­ ê²°ê³¼ ì €ì¥ ì¤‘...")
            extractor.entries = entries
            extractor.save(output_path / "extracted_translated.json")

            # 5. translation_entries ìƒì„± (Excel ë‚´ë³´ë‚´ê¸°ìš©)
            self.progress.emit(88, "ì—‘ì…€ ë°ì´í„° ìƒì„± ì¤‘...")
            translation_entries = []
            for entry in entries:
                if entry.translated:
                    translation_entries.append({
                        'file': entry.context.get('file', 'unknown'),
                        'original': entry.text,
                        'translated': entry.translated,
                        'context': entry.context
                    })

            # 6. ê²Œì„ì— ì ìš© (preview_modeê°€ ì•„ë‹Œ ê²½ìš°)
            if not self.preview_mode:
                self.progress.emit(92, "ê²Œì„ íŒŒì¼ì— ë²ˆì—­ ì ìš© ì¤‘...")

                from cli.patcher import UnityPatcher

                # ë°±ì—… ìƒì„± í›„ íŒ¨ì¹˜ ì ìš©
                patcher = UnityPatcher(input_path, backup=True)
                success = patcher.apply_patches(entries)

                if success:
                    apply_msg = "\nâœ… ê²Œì„ íŒŒì¼ì— ë²ˆì—­ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!"
                else:
                    apply_msg = "\nâš ï¸ ê²Œì„ íŒŒì¼ ì ìš© ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ"
            else:
                apply_msg = "\nğŸ’¡ 'ê²Œì„ì— ì ìš©í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²Œì„ì— ì ìš©í•˜ì„¸ìš”."

            # 7. ë¹„ìš© ê³„ì‚°
            cost_info = self.calculate_cost()

            # 8. ì™„ë£Œ ë©”ì‹œì§€
            completion_msg = (
                f"âœ… ì¼ë°˜ Unity ê²Œì„ ë²ˆì—­ ì™„ë£Œ!\n\n"
                f"ğŸ“Š ìƒˆë¡œ ë²ˆì—­: {translated_count}ê°œ\n"
                f"â­ï¸ ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ë²ˆì—­): {skipped_count}ê°œ\n"
                f"ğŸ“ ì´ í•­ëª©: {len(entries)}ê°œ\n"
                f"ğŸ’° ë¹„ìš©: ${cost_info['total_cost']:.4f}\n\n"
                f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}{apply_msg}"
            )

            self.progress.emit(100, "ì™„ë£Œ")
            self.finished.emit(completion_msg, cost_info, translation_entries, translated_count)

        except Exception as e:
            import traceback
            self.error.emit(f"âŒ Unity ê²Œì„ ë²ˆì—­ ì‹¤íŒ¨:\n{str(e)}\n\n{traceback.format_exc()}")

    def _translate_rpgmaker_game(self):
        """RPG Maker ê²Œì„ ë²ˆì—­ ì²˜ë¦¬"""
        try:
            from core.rpgmaker_extractor import RPGMakerDialogueExtractor
            from core.translator import UniversalTranslator
            from security.secure_storage import SecureStorage
            import os
            import json

            input_path = Path(self.input_dir)
            output_path = Path(self.output_dir)
            output_path.mkdir(parents=True, exist_ok=True)

            # 1. ëŒ€ì‚¬ ì¶”ì¶œ
            self.progress.emit(10, "RPG Maker ëŒ€ì‚¬ ì¶”ì¶œ ì¤‘...")
            print(f"ğŸ“¦ RPG Maker ê²Œì„ì—ì„œ ëŒ€ì‚¬ ì¶”ì¶œ ì¤‘: {input_path}")

            extractor = RPGMakerDialogueExtractor(input_path)
            dialogues = extractor.extract_all()

            if not dialogues or len(dialogues) == 0:
                self.error.emit(
                    "âŒ ë²ˆì—­ ê°€ëŠ¥í•œ ëŒ€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                    "ê°€ëŠ¥í•œ ì›ì¸:\n"
                    "- data í´ë”ê°€ ì—†ê±°ë‚˜ Map íŒŒì¼ì´ ì—†ìŒ\n"
                    "- JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ"
                )
                return

            self.progress.emit(20, f"{len(dialogues)}ê°œ ëŒ€ì‚¬ ë°œê²¬")
            print(f"âœ… {len(dialogues)}ê°œ ëŒ€ì‚¬ ì¶”ì¶œ ì™„ë£Œ")

            # 2. API í‚¤ í™•ì¸
            self.progress.emit(25, "API í‚¤ í™•ì¸ ì¤‘...")
            storage = SecureStorage()

            api_key = None
            if "Claude" in self.engine:
                api_key = storage.get_api_key("claude")
                if not api_key:
                    self.error.emit("âŒ Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                    return
                os.environ["ANTHROPIC_API_KEY"] = api_key

            # 3. ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ (ë²ˆì—­ ë©”ëª¨ë¦¬)
            existing_json = output_path / "extracted_translated.json"
            existing_translations = {}

            if existing_json.exists():
                self.progress.emit(28, "ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ ì¤‘...")
                try:
                    with open(existing_json, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)

                    for entry in existing_data:
                        original_text = entry.get('original', '')
                        translated_text = entry.get('translated', '')
                        if original_text and translated_text:
                            existing_translations[original_text] = translated_text

                    print(f"âœ… ê¸°ì¡´ ë²ˆì—­ {len(existing_translations)}ê°œ ë¡œë“œë¨")
                except Exception as e:
                    print(f"âš ï¸ ê¸°ì¡´ ë²ˆì—­ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

            # 4. ë²ˆì—­
            self.progress.emit(30, f"{len(dialogues)}ê°œ ëŒ€ì‚¬ ë²ˆì—­ ì‹œì‘...")

            translator = UniversalTranslator(
                source_lang=self.source_lang,
                target_lang=self.target_lang,
                engine=self.engine
            )

            translated_count = 0
            skipped_count = 0

            # ê³ ìœ í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
            unique_texts = {}
            for dialogue in dialogues:
                text = dialogue['original']
                if text not in unique_texts:
                    unique_texts[text] = None

            print(f"ğŸ“Š ê³ ìœ  ëŒ€ì‚¬: {len(unique_texts)}ê°œ (ì „ì²´ {len(dialogues)}ê°œ)")

            # íŒ¨í„´ ê°ì§€ (5íšŒ ì´ìƒ ë°˜ë³µ)
            self.progress.emit(30, "ë°˜ë³µ íŒ¨í„´ ê°ì§€ ì¤‘...")
            patterns = self._find_patterns(list(unique_texts.keys()), min_count=5)
            pattern_hits = 0

            if patterns:
                print(f"ğŸ” {len(patterns)}ê°œ íŒ¨í„´ ë°œê²¬ (5íšŒ ì´ìƒ ë°˜ë³µ)")
                # íŒ¨í„´ë³„ ë²ˆì—­
                for pattern_template, items in patterns.items():
                    # íŒ¨í„´ í…œí”Œë¦¿ ë²ˆì—­ (ì˜ˆì‹œ ìˆ«ì ì‚¬ìš©)
                    example_text = pattern_template.replace('{NUM}', '10')
                    pattern_translation = translator.translate(example_text)

                    # ìˆ«ìë¥¼ ë‹¤ì‹œ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì¹˜í™˜
                    import re
                    pattern_translation = re.sub(r'\d+', '{NUM}', pattern_translation)

                    # ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ì— ì ìš©
                    for item in items:
                        original_text = item['text']
                        numbers = item['numbers']

                        # í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ìˆ«ìë¡œ ì¹˜í™˜
                        translated = pattern_translation
                        for num in numbers:
                            translated = translated.replace('{NUM}', num, 1)

                        unique_texts[original_text] = translated
                        pattern_hits += 1

                print(f"âœ… íŒ¨í„´ ë²ˆì—­: {pattern_hits}ê°œ (API ì ˆê°: {pattern_hits - len(patterns)}íšŒ)")
            else:
                print("â„¹ï¸ ë°˜ë³µ íŒ¨í„´ ì—†ìŒ")

            # ì‚¬ì „ ë¡œë“œ
            dict_hits = 0
            proper_nouns_dict = self._load_dictionary("config/dicts/proper_nouns.json")
            speaker_dict = self._load_dictionary("config/dicts/speaker_names.json")
            interjection_dict = self._load_dictionary("config/dicts/interjections.json")

            print(f"ğŸ“š ì‚¬ì „ ë¡œë“œ ì™„ë£Œ:")
            print(f"   - ê³ ìœ ëª…ì‚¬: {len(proper_nouns_dict)}ê°œ")
            print(f"   - í™”ìëª…: {len(speaker_dict)}ê°œ")
            print(f"   - ê°íƒ„ì‚¬: {len(interjection_dict)}ê°œ")

            # ì‚¬ì „ ì ìš© (ì™„ì „ ì¼ì¹˜ & ë¶€ë¶„ ì¹˜í™˜)
            self.progress.emit(32, "ì‚¬ì „ ì ìš© ì¤‘...")
            all_dicts = {**proper_nouns_dict, **speaker_dict, **interjection_dict}
            partial_dicts = {**proper_nouns_dict, **speaker_dict}  # ê°íƒ„ì‚¬ ì œì™¸

            texts_need_translation = {}
            for text in unique_texts.keys():
                # 0. ì´ë¯¸ íŒ¨í„´ìœ¼ë¡œ ë²ˆì—­ëœ í•­ëª© ê±´ë„ˆë›°ê¸°
                if unique_texts[text] is not None:
                    continue

                # 1. ì™„ì „ ì¼ì¹˜ ì²´í¬ (ëª¨ë“  ì‚¬ì „)
                if text in all_dicts:
                    unique_texts[text] = all_dicts[text]
                    dict_hits += 1
                    continue

                # 2. ë¶€ë¶„ ì¹˜í™˜ (ê³ ìœ ëª…ì‚¬ + í™”ìëª…ë§Œ)
                text_to_translate = text
                for jp, ko in partial_dicts.items():
                    if jp in text_to_translate and jp != text_to_translate:
                        text_to_translate = text_to_translate.replace(jp, ko)

                # ë²ˆì—­ í•„ìš” í•­ëª©ì— ì¶”ê°€
                texts_need_translation[text] = text_to_translate

            print(f"ğŸ“– ì‚¬ì „ ì ìš©: {dict_hits}ê°œ (ë²ˆì—­ í•„ìš”: {len(texts_need_translation)}ê°œ)")

            # ë°°ì¹˜ ë²ˆì—­
            texts_list = list(texts_need_translation.items())  # (ì›ë³¸, ì¹˜í™˜ëœ í…ìŠ¤íŠ¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            for i in range(0, len(texts_list), self.batch_size):
                batch = texts_list[i:i+self.batch_size]

                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                progress_pct = 35 + int((i / len(texts_list)) * 55)
                self.progress.emit(progress_pct, f"ë²ˆì—­ ì¤‘... ({i}/{len(texts_list)})")

                # ë°°ì¹˜ ì•„ì´í…œ ì¤€ë¹„
                batch_originals = []  # ì›ë³¸ í…ìŠ¤íŠ¸
                batch_to_translate = []  # ë²ˆì—­í•  í…ìŠ¤íŠ¸ (ë¶€ë¶„ ì¹˜í™˜ ì ìš©ë¨)

                for original_text, text_to_translate in batch:
                    # ê¸°ì¡´ ë²ˆì—­ í™•ì¸
                    if original_text in existing_translations:
                        unique_texts[original_text] = existing_translations[original_text]
                        skipped_count += 1
                    else:
                        batch_originals.append(original_text)
                        batch_to_translate.append(text_to_translate)

                # ìƒˆë¡œìš´ í•­ëª©ë§Œ ë²ˆì—­
                if batch_to_translate:
                    # ì„±ì¸ ì½˜í…ì¸  ê²€ì—´ ìš°íšŒ (ë¯¼ê°í•œ ë‹¨ì–´ ìˆìœ¼ë©´)
                    bypass_censorship = any(
                        any(term in text for term in ["ãŠã£ã±ã„", "ã‚»ãƒƒã‚¯ã‚¹", "ã¡ã‚“ã½", "ã¾ã‚“ã“", "ç²¾æ¶²"])
                        for text in batch_to_translate
                    )

                    if self.batch_size == 1 or len(batch_to_translate) == 1:
                        # ê°œë³„ ë²ˆì—­
                        for original, to_translate in zip(batch_originals, batch_to_translate):
                            translation = translator.translate(to_translate)
                            unique_texts[original] = translation
                            translated_count += 1

                            # í† í° ë° ë¹„ìš© ëˆ„ì 
                            if hasattr(translator, 'last_usage'):
                                usage = translator.last_usage
                                self.total_tokens["input"] += usage.get("input_tokens", 0)
                                self.total_tokens["output"] += usage.get("output_tokens", 0)
                    else:
                        # ë°°ì¹˜ ë²ˆì—­ (ê²€ì—´ ìš°íšŒ ì˜µì…˜ ì‚¬ìš©)
                        translations = translator.translate_batch(
                            batch_to_translate,
                            bypass_censorship=bypass_censorship
                        )
                        for original, translation in zip(batch_originals, translations):
                            unique_texts[original] = translation
                            translated_count += 1

                        # í† í° ë° ë¹„ìš© ëˆ„ì 
                        if hasattr(translator, 'last_usage'):
                            usage = translator.last_usage
                            self.total_tokens["input"] += usage.get("input_tokens", 0)
                            self.total_tokens["output"] += usage.get("output_tokens", 0)

                # ì£¼ê¸°ì ìœ¼ë¡œ ì €ì¥ (50ê°œë§ˆë‹¤)
                if (i + self.batch_size) % 50 == 0:
                    # ë²ˆì—­ ì ìš©
                    for dialogue in dialogues:
                        original = dialogue['original']
                        dialogue['translated'] = unique_texts.get(original, '')

                    # ì„ì‹œ ì €ì¥
                    temp_file = output_path / "extracted_translated.json"
                    with open(temp_file, 'w', encoding='utf-8') as f:
                        json.dump(dialogues, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {i + self.batch_size}/{len(texts_list)}")

            # 5. ë²ˆì—­ ì ìš©
            self.progress.emit(90, "ë²ˆì—­ ê²°ê³¼ ì ìš© ì¤‘...")
            for dialogue in dialogues:
                original = dialogue['original']
                dialogue['translated'] = unique_texts.get(original, '')

            # 6. ìµœì¢… ì €ì¥
            self.progress.emit(95, "ë²ˆì—­ ê²°ê³¼ ì €ì¥ ì¤‘...")
            output_file = output_path / "extracted_translated.json"

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(dialogues, f, ensure_ascii=False, indent=2)

            print(f"âœ… ë²ˆì—­ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            print(f"âœ… ë²ˆì—­ ê²°ê³¼ ì €ì¥: {len(dialogues)}ê°œ í•­ëª©")

            # 7. translation_entries ìƒì„± (Excel ë‚´ë³´ë‚´ê¸°ìš©)
            self.progress.emit(98, "ì—‘ì…€ ë°ì´í„° ìƒì„± ì¤‘...")
            self.translation_entries = dialogues  # RPG MakerëŠ” ì´ë¯¸ ì ì ˆí•œ í˜•ì‹

            # 8. ë¹„ìš© ê³„ì‚°
            cost_info = self.calculate_cost()

            # 9. ì™„ë£Œ ë©”ì‹œì§€
            completion_msg = (
                f"âœ… RPG Maker ê²Œì„ ë²ˆì—­ ì™„ë£Œ!\n\n"
                f"ğŸ“Š ìƒˆë¡œ ë²ˆì—­: {translated_count}ê°œ\n"
                f"â­ï¸ ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ë²ˆì—­): {skipped_count}ê°œ\n"
                f"ğŸ“ ì´ ëŒ€ì‚¬: {len(dialogues)}ê°œ\n"
                f"ğŸ’° ë¹„ìš©: ${cost_info['total_cost']:.4f}\n\n"
                f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}\n\n"
                f"ğŸ’¡ 'Excel ë‚´ë³´ë‚´ê¸°'ë¡œ ê²€ìˆ˜í•˜ê±°ë‚˜ 'ê²Œì„ì— ì ìš©í•˜ê¸°'ë¡œ ê²Œì„ì— ì ìš©í•˜ì„¸ìš”."
            )

            self.progress.emit(100, "ì™„ë£Œ")
            self.finished.emit(completion_msg, cost_info, self.translation_entries, translated_count)

        except Exception as e:
            import traceback
            self.error.emit(f"âŒ RPG Maker ê²Œì„ ë²ˆì—­ ì‹¤íŒ¨:\n{str(e)}\n\n{traceback.format_exc()}")
